{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLpFPbjHBuqDid2WlVHgYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22Ifeoma22/22Ifeoma22/blob/main/Copy_of_Exercise_Autooff_Agorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the torch package and matplotlib for graphics\n",
        "## Explained using Multivariate Linear Regression in Pytorch and Python"
      ],
      "metadata": {
        "id": "prCSB11aK2mn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distributied Gradient Descent\n",
        "in this notebook,you can learn about\n",
        "\n",
        "\n",
        "*   gradient descent with gradient accumulation\n",
        "*   deep learning with training datasets that do not fit in node memory\n",
        "*   gradient accumulation in parameter servser-based vs ring-based(for example Horovod)gradient descent\n",
        "*   Reduce-Scater and reduce-all phases in Horovod\n",
        "*   Horovod as an implementation for distributed data parallel training in deep learning\n",
        "\n",
        "Why shouldwe care? Are you:\n",
        "\n",
        "\n",
        "*   Informing deep learning platform buy vs. build decision for your project, team, or organisation\n",
        "*   Scaling up your deep learning models to out-of-memory training datasets\n",
        "*   Understanding of troubleshooting distributed deep learning training\n",
        "*   researching the direction of high performance distributed deep learning\n",
        "*   working on federated deep learning or bandwidth-constrained(IOT)training at cloud's edge\n",
        "This notenbook builds on the gradient descent, differentiation, tensors, and other concepts introduced in\n",
        "\n",
        "\n",
        "*   Automatic Differentiation Explained\n",
        "*   Bandwidth Optimal All-reduce Algorithms\n",
        "*   Bring HPC Techniques to Deep learning\n"
      ],
      "metadata": {
        "id": "8yvTYLGkZupI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as pt\n",
        "%matplotlib inline\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "SEED = 42\n",
        "pt.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "pt.__version__, np.__version__, pd.__version__ # Use __version__ (lowercase v) to access version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwq7x9WYiU8V",
        "outputId": "1069d7b3-a6dd-4418-914e-427c6e6a749e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.3.1+cu121', '1.25.2', '2.0.3')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a training dataset of features for multivariate linear regreassion\n",
        "\n",
        "\n",
        "\n",
        "*   TRAINING_DATASET_SIZE is pre-set to a default of 1,000\n",
        "* Assume that FEATURES is set to 4  \n",
        "\n"
      ],
      "metadata": {
        "id": "1lbONd2Viab6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DATASET_SIZE = 1000\n",
        "FEATURES = 4"
      ],
      "metadata": {
        "id": "PDOV7gJ5iYDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a NumPy nd-array named x_numpy with a shape of (TRAINING_DATASET_SIZE, FEATURES):\n",
        "*   The array should contain features values shuch that the values in each column are from a normal\n",
        "(bell-shaped) distribution.\n",
        "*   The means of the features values should be 0.0 for the first column, 1.0 for the second column, and so on.\n",
        "*   The feature values across columns should be uncorrelated.\n",
        "\n",
        " **HINT**:You can use np.random.multivariate_normal to create x_numpy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jvl58eRbjIEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_numpy = np.random.multivariate_normal(np.arange(FEATURES), np.eye(FEATURES), TRAINING_DATASET_SIZE )\n",
        "X_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moQ1ZJrrkqra",
        "outputId": "af614bdc-5fac-4bc3-e593-2c05ef6b89d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.49671415,  0.8617357 ,  2.64768854,  4.52302986],\n",
              "       [-0.23415337,  0.76586304,  3.57921282,  3.76743473],\n",
              "       [-0.46947439,  1.54256004,  1.53658231,  2.53427025],\n",
              "       ...,\n",
              "       [ 1.92344579,  0.22538503,  0.31081696,  2.52873626],\n",
              "       [-1.97548777,  1.75109945, -0.06508305,  3.02845758],\n",
              "       [-2.07781182,  0.6797022 ,  3.64337816,  3.36064789]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check that a column's feature values are normal\n",
        "Hint: You can use the matplotlib.pyplot.hist Method."
      ],
      "metadata": {
        "id": "P0_TxnpMpkEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ... (your existing code)\n",
        "\n",
        "plt.hist(X_numpy[:, 0], bins=30)  # Removed semicolon, which isn't necessary here\n",
        "plt.hist(X_numpy[:, 3], bins=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "WNAgkz44sctY",
        "outputId": "ea340346-fa05-4485-9a91-570bee0b4c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confirm that the feature values are incorrelated across columns\n",
        "**Hint**: You can see the pandas.DataFrame.corr method"
      ],
      "metadata": {
        "id": "ucy4lbbrs7wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_numpy).corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "cKaHHGpOpzZN",
        "outputId": "8b7fb93f-097f-47ff-f9df-aaa218230125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3\n",
              "0  1.000000  0.008146 -0.038208 -0.022976\n",
              "1  0.008146  1.000000 -0.032355  0.004602\n",
              "2 -0.038208 -0.032355  1.000000  0.033745\n",
              "3 -0.022976  0.004602  0.033745  1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a966d5b6-f5bd-4e19-872b-5d92ff60bd04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>-0.038208</td>\n",
              "      <td>-0.022976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008146</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.032355</td>\n",
              "      <td>0.004602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.038208</td>\n",
              "      <td>-0.032355</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.033745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.022976</td>\n",
              "      <td>0.004602</td>\n",
              "      <td>0.033745</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a966d5b6-f5bd-4e19-872b-5d92ff60bd04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a966d5b6-f5bd-4e19-872b-5d92ff60bd04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a966d5b6-f5bd-4e19-872b-5d92ff60bd04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc36fd17-447e-46d9-94e2-80f32f1de88e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc36fd17-447e-46d9-94e2-80f32f1de88e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc36fd17-447e-46d9-94e2-80f32f1de88e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5092052118421064,\n        \"min\": -0.03820817524468657,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.008146321813025619,\n          -0.022976089076358727,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.503600933117783,\n        \"min\": -0.032355087062622294,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          0.004601936432535832,\n          0.008146321813025619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5071869596035545,\n        \"min\": -0.03820817524468657,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.032355087062622294,\n          0.033744614605008126,\n          -0.03820817524468657\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4979770689992317,\n        \"min\": -0.022976089076358727,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.004601936432535832,\n          1.0,\n          -0.022976089076358727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a PyTorch tensor X_train from X_numpy\n",
        "\n",
        "*  You can use PyTorch's from_numpy function to resue the in-memory data allocated by a NumPy nd-array\n",
        "\n",
        "* Ensure that the resulting PyTorch tensor has a shape of (Training_Dataset_size,FEATURES)\n",
        "\n"
      ],
      "metadata": {
        "id": "6l7DlTlUtk50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pt.tensor(X_numpy,dtype=pt.float64).reshape(TRAINING_DATASET_SIZE, FEATURES)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVH6Qt5KufLL",
        "outputId": "fc6aef7a-cd51-443c-955f-b80fcf6dd774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4967,  0.8617,  2.6477,  4.5230],\n",
              "        [-0.2342,  0.7659,  3.5792,  3.7674],\n",
              "        [-0.4695,  1.5426,  1.5366,  2.5343],\n",
              "        ...,\n",
              "        [ 1.9234,  0.2254,  0.3108,  2.5287],\n",
              "        [-1.9755,  1.7511, -0.0651,  3.0285],\n",
              "        [-2.0778,  0.6797,  3.6434,  3.3606]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the COEFFICIENTS tensor is pre-defined as [5, 3, 2, 1] just to make the linear regression easier to visualize in the upcoming cells"
      ],
      "metadata": {
        "id": "hhysMb29u39s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COEFFICIENTS = pt.tensor([5, 3, 2, 1])\n",
        "COEFFICIENTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZZJiWIyvXbb",
        "outputId": "8c265563-148b-4ab9-bbfa-2c37e806c003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 3, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a y_train tensor using COEFFICIENTS and X_train\n",
        "\n",
        "Gradient descent will atempt to recover the COEFFICIENTS and X_train\n",
        "\n",
        "Gradient descesnt will ateempt to recover the COEFFICIENS using just the y_train and X_train values.\n",
        "*   Ensure that y_train has a shape of (TRAINING_DATASET_SIZE)\n",
        "*   \n",
        "\n"
      ],
      "metadata": {
        "id": "aQzJiRy32BAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert COEFFICIENTS to have the same type as X_train\n",
        "COEFFICIENTS = COEFFICIENTS.double()\n",
        "\n",
        "# Perform the matrix multiplication\n",
        "y_train = X_train @ COEFFICIENTS\n",
        "y_train = y_train.reshape(TRAINING_DATASET_SIZE)\n",
        "y_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agu6RjzO-gis",
        "outputId": "3d544d2f-f59f-4d4e-a131-cf9eaeb06cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.4887e+01,  1.2053e+01,  7.8877e+00,  1.4578e+00,  2.6502e+00,\n",
              "         1.5361e+01,  5.6846e+00,  6.7706e+00,  7.1836e+00,  2.7058e+00,\n",
              "         1.3674e+01,  5.8370e-01,  6.6921e+00,  1.1444e+01,  6.5143e+00,\n",
              "         3.6383e+00,  1.8991e+01,  1.2134e+01,  1.0097e+01,  7.7342e+00,\n",
              "         1.2410e+01,  6.6118e+00,  1.0054e+01,  3.2590e+00,  1.2039e+01,\n",
              "         1.7350e-01,  1.4353e+01,  7.2004e+00,  1.7608e+01,  9.3580e+00,\n",
              "         1.2631e+01,  1.6958e+01,  5.9551e+00,  5.8203e+00,  5.5137e+00,\n",
              "         1.2028e+01,  9.8505e+00,  1.4348e+01,  7.1684e+00,  1.9024e+01,\n",
              "         8.9844e+00,  1.9596e+01,  3.9170e+00,  1.2019e+01,  1.6616e+01,\n",
              "         8.8976e+00,  1.1898e+01,  1.1849e+00,  8.0649e+00,  5.0153e+00,\n",
              "         1.6691e+01,  1.8420e+00,  2.6411e+01,  1.6853e+01,  4.5366e+00,\n",
              "         1.5731e+01,  9.9580e+00,  7.2180e+00,  1.3195e+01, -3.7490e-02,\n",
              "         7.5689e+00,  1.3918e+00,  1.8438e+01,  2.0185e+01,  1.5874e+01,\n",
              "        -2.3202e+00,  6.8285e+00,  9.6387e+00,  1.4346e+01,  8.9489e+00,\n",
              "         1.4488e+01,  1.5094e+01,  8.6276e+00,  9.6231e+00,  1.7675e+01,\n",
              "         6.2794e+00,  1.2211e+01,  1.2792e+01,  1.9200e+01,  1.2997e+01,\n",
              "         1.2726e+01,  4.4352e+00,  1.4084e+01,  1.0151e+01,  5.1705e+00,\n",
              "         6.6029e+00,  4.0373e+00,  7.8646e+00,  1.2768e+01,  8.8597e+00,\n",
              "         1.7379e+01,  1.2708e+01,  8.7164e+00,  2.3673e+01,  1.8483e+01,\n",
              "        -7.7033e-01,  9.2152e+00,  1.1716e+01,  1.0783e+01,  6.5047e+00,\n",
              "         2.8720e-01,  7.3406e+00,  1.2443e+01,  6.0786e+00,  2.0529e+01,\n",
              "         2.6043e+01,  1.6089e+01,  5.6102e+00,  1.3884e+01,  1.0540e+01,\n",
              "         7.5982e+00,  5.2800e+00,  5.0828e+00,  4.7301e+00,  4.0539e+00,\n",
              "         1.8744e+01,  1.0761e+01,  2.7680e+00,  9.5656e+00,  2.1094e+01,\n",
              "         3.4844e+00, -4.2321e-01,  2.2545e+01,  1.1388e+01,  1.1087e+00,\n",
              "         1.8125e+01,  3.2366e+00,  8.2404e+00,  5.6844e+00,  1.0522e+01,\n",
              "         2.5284e+00, -2.4379e+00,  8.2013e+00,  4.7803e+00,  5.9800e+00,\n",
              "         1.3291e+01, -3.7978e+00,  1.0061e+01,  1.6866e+01,  6.6322e+00,\n",
              "         1.9091e+01,  9.6975e+00,  1.3048e+00,  1.0425e+01,  1.1677e+01,\n",
              "         1.3983e+01,  9.8854e+00,  1.1249e+01,  1.4961e+01,  5.2030e+00,\n",
              "         1.4113e+01,  1.4905e+01,  6.8477e+00,  1.3044e+01,  1.3910e+01,\n",
              "         1.2572e+01,  1.4327e+01,  1.1706e+01,  4.2503e+00,  1.0461e+01,\n",
              "         1.1306e+01,  2.5050e+00,  1.5758e+01,  1.0542e+01,  1.0249e+01,\n",
              "         4.8822e+00,  7.7491e+00,  4.3845e-01,  3.5794e+00,  1.2847e+01,\n",
              "         9.6615e+00,  5.1729e+00,  1.5325e+01,  7.3191e+00,  9.5405e+00,\n",
              "         7.7163e+00,  3.2288e+00,  5.0050e+00,  9.5008e+00,  1.0238e+01,\n",
              "         4.4554e+00,  1.0687e+01,  4.3796e+00,  9.4644e+00,  1.8574e+01,\n",
              "        -4.2666e+00,  1.0029e+01, -4.7572e-01,  9.0151e+00,  1.2005e+01,\n",
              "         1.2512e+01,  1.5338e+01,  1.3156e+01,  1.5753e+01,  6.0936e+00,\n",
              "         8.2535e+00,  1.8168e+01,  5.7332e+00,  6.4187e+00,  1.1933e+01,\n",
              "         1.2873e+01,  6.8655e+00,  1.2781e+01,  1.8403e+01,  1.5234e+01,\n",
              "         1.5877e+01,  1.4769e+01,  3.4462e+00,  2.8407e+00,  1.6512e+01,\n",
              "         9.9141e+00,  1.5343e+01,  3.4166e+00,  1.2650e+01,  6.7810e+00,\n",
              "         1.1358e+01,  6.6791e+00,  1.8171e+01,  2.6389e+00,  9.2389e+00,\n",
              "         2.1107e+01,  1.9758e+01,  1.8428e+01,  2.2254e+01,  1.1201e+01,\n",
              "         1.1999e+01,  9.1213e+00,  1.9321e+01,  1.6068e+01,  1.2901e+01,\n",
              "         1.1854e+01,  1.0665e+01,  1.8401e+01, -3.4585e+00,  6.9424e+00,\n",
              "         7.4171e+00,  1.2280e+01,  1.0372e+01,  9.0266e+00,  1.4671e+01,\n",
              "         1.8303e+01,  1.4320e+01,  5.0820e+00,  9.4634e+00, -1.9406e+00,\n",
              "         1.3224e+01,  1.0391e+01,  7.3509e+00,  4.4338e+00,  2.0341e+01,\n",
              "         1.9243e+01,  1.7097e+01,  1.6474e+01,  2.1979e+01,  5.0747e+00,\n",
              "         1.2987e+01,  2.0143e+01,  7.8159e+00,  1.4545e+01,  9.7405e-01,\n",
              "         1.9162e+01,  1.1516e+01,  2.0668e+01,  1.1480e+01,  1.4107e+01,\n",
              "         5.8707e+00,  3.4002e+00,  9.0842e+00,  8.0339e+00,  4.7845e+00,\n",
              "         8.6424e+00,  1.5499e+01,  7.9353e+00,  1.5179e+01,  6.5777e+00,\n",
              "         1.0338e+01,  1.2593e+01,  1.2459e+01,  1.6503e+01,  2.3297e+01,\n",
              "         1.9223e+01,  1.4579e+01,  1.1730e+01,  1.9905e+01,  1.4161e+01,\n",
              "         1.2465e+01,  5.5488e+00,  1.1295e+01,  7.1298e+00,  1.4955e+01,\n",
              "        -4.8745e-02,  2.5765e+01,  1.7333e+01,  8.5446e+00, -1.8406e+00,\n",
              "         1.5342e+01,  5.6846e+00,  8.7220e+00,  5.2070e+00,  1.3371e+01,\n",
              "         1.0126e+01,  8.2992e+00,  5.0551e+00,  9.7506e+00,  7.9440e+00,\n",
              "         6.6728e+00,  8.6247e+00,  1.8966e+01,  1.7329e+01,  1.9494e+01,\n",
              "         5.3155e+00,  2.3800e+00,  7.9965e+00,  2.3992e+00,  1.8154e+01,\n",
              "         1.3176e+01,  5.4793e+00,  1.2822e+01,  6.1571e+00,  2.2852e+01,\n",
              "         1.2583e+01, -1.0881e+00,  1.2947e+00,  1.2550e+01,  1.4581e+01,\n",
              "         8.5300e+00,  1.0034e+01,  1.7621e+01,  1.7333e+01,  2.3528e+00,\n",
              "         1.2218e+01,  2.3732e+00,  1.0032e+01,  1.3365e+01,  5.4196e+00,\n",
              "         1.2877e+01,  6.1196e+00, -1.6509e+00,  1.1241e+01,  5.6697e+00,\n",
              "         1.0927e+01,  1.4519e+01,  6.4950e+00,  1.0328e+00,  1.0389e+01,\n",
              "         1.5635e+01,  1.8773e+01,  8.1420e+00,  1.9931e+01,  2.0935e+00,\n",
              "         9.4658e+00,  1.1368e+01,  1.0847e+01,  1.8415e+01,  1.4656e+01,\n",
              "         1.4340e+01,  1.8861e+00,  9.4938e+00,  1.2501e+01,  1.5295e+01,\n",
              "         1.5900e+01,  9.5735e+00,  1.8575e+01,  1.8379e+01,  1.8163e+01,\n",
              "         4.3663e+00,  1.2598e+01,  7.1379e+00,  8.4525e+00,  8.4414e+00,\n",
              "         1.5548e+01,  9.3237e+00,  7.6140e+00,  1.2823e+01,  2.6573e+01,\n",
              "         1.0598e+01,  1.0137e+01,  1.2398e+01,  5.2917e-01,  1.9265e+01,\n",
              "         1.6439e+01,  1.6718e+01,  2.7102e+00,  8.6463e+00,  5.7578e+00,\n",
              "         1.8045e+01,  6.7003e+00,  1.7107e+01,  3.0439e+00,  1.4873e+01,\n",
              "         3.6871e+00,  1.3490e+01,  9.3435e-01,  8.2953e+00,  3.1391e+00,\n",
              "         1.2479e+01,  1.4209e+01,  1.0549e+00,  9.1590e+00,  1.8582e+01,\n",
              "         1.1119e+01,  6.5963e+00,  8.7115e+00,  1.7014e+01,  9.5341e+00,\n",
              "         7.4218e+00,  2.2993e+01,  1.3021e+01,  8.7989e+00,  9.5527e+00,\n",
              "         1.4651e+01,  6.5844e+00,  2.5191e+01,  1.0294e+01,  1.3922e+01,\n",
              "         1.1380e+01,  1.3913e+01,  1.4999e+01,  8.1824e+00,  2.2215e+01,\n",
              "         1.0463e+01,  6.9398e+00,  1.1338e+01,  1.2510e+01,  4.1725e+00,\n",
              "         1.5600e+01,  1.4570e+01,  8.5070e+00,  5.1773e-01,  1.3215e+01,\n",
              "         1.3880e+01,  8.3169e+00,  1.6555e+01,  8.9769e+00,  5.1394e+00,\n",
              "         1.0273e+01,  8.5298e+00,  9.2225e+00,  3.6338e+00,  1.6711e+01,\n",
              "         1.8975e+01,  1.0406e+01,  1.4053e+01,  4.6656e+00,  5.2790e+00,\n",
              "         4.6971e-01,  4.6690e+00,  1.1982e+01,  1.0888e+01,  8.1900e+00,\n",
              "         1.6393e+01, -2.7251e+00,  3.9598e+00,  1.9323e+01, -4.3260e+00,\n",
              "         8.4746e+00,  1.1399e+01,  1.1213e+01,  1.4764e+01,  4.3325e+00,\n",
              "         2.7072e+00,  9.3815e+00,  1.6612e+01,  8.1198e+00,  1.7050e+01,\n",
              "         1.1599e+01,  1.4726e+01,  8.8639e-01,  1.4815e+01,  2.3887e+00,\n",
              "         1.6610e+01,  9.5133e+00,  8.6864e+00,  6.9425e+00,  1.4328e+01,\n",
              "         1.5199e+01,  6.5381e+00,  1.0156e+01,  1.0548e+01,  3.3902e+00,\n",
              "         4.4099e-01,  1.2266e+01,  1.9417e+01,  1.1141e+01,  1.4941e+01,\n",
              "         1.0560e+01,  1.2724e+01,  1.3192e+01,  3.6932e+00,  1.1070e+01,\n",
              "         1.2270e+01,  1.2501e+01,  1.0673e+01,  1.3438e+01,  1.7324e+01,\n",
              "         6.1182e-01,  1.8271e+01,  1.0443e+01,  1.9843e+01,  6.1507e+00,\n",
              "         4.2978e+00,  3.5713e-01,  1.2131e+01,  4.7997e+00,  2.6974e+00,\n",
              "         1.2544e+01,  2.9396e-01,  1.0214e+01,  1.8778e+01,  8.6150e+00,\n",
              "         4.4028e+00,  9.2421e+00,  9.6092e+00,  2.2872e+00,  1.0961e+01,\n",
              "         1.4520e+01,  4.5666e+00,  2.3059e+01,  9.4839e+00,  1.5961e+01,\n",
              "         6.6224e+00,  2.4211e+00,  1.3045e+01,  1.1697e+01,  7.8472e+00,\n",
              "         8.5620e+00,  7.8181e+00,  8.9154e+00,  8.1665e+00,  5.5826e-01,\n",
              "         2.4115e+01,  1.0506e+01,  1.6628e+01,  1.3858e+01,  1.1211e+01,\n",
              "         1.1567e+01,  9.3233e+00,  5.8639e+00,  7.6598e+00,  1.0292e+01,\n",
              "         7.3188e+00,  1.1978e+01,  1.2128e+01,  9.2753e+00,  6.5699e+00,\n",
              "         8.9895e+00,  4.2642e-01,  6.8854e+00,  1.5749e+01,  1.1392e+01,\n",
              "         1.8595e+01,  9.9589e+00,  6.5363e+00,  1.2381e+01,  1.1570e+01,\n",
              "         7.5728e+00,  1.2956e+01,  3.1112e+00,  1.1357e+00,  7.0818e+00,\n",
              "         1.4671e+01,  1.5271e+01,  1.3075e+01,  5.6670e-01,  8.1627e+00,\n",
              "         1.4797e+01,  1.3741e+01,  7.4427e+00,  3.4636e+00,  1.1746e+01,\n",
              "         7.4533e-01,  1.0379e+01,  1.5736e+01,  6.8634e+00,  1.6095e+01,\n",
              "         1.1748e+01,  3.0338e+01,  1.6489e+01,  1.4397e+01,  1.0126e+01,\n",
              "         1.7124e+01,  9.4077e+00,  1.5365e+01,  3.6955e+00,  1.2006e+01,\n",
              "         1.5215e+01,  7.0429e-01,  1.5028e+01,  1.2005e+01,  5.4400e+00,\n",
              "        -1.1369e+00,  8.6759e+00,  7.2647e+00,  1.5989e+01,  3.6564e+00,\n",
              "         2.9487e+00,  6.5035e+00,  1.2935e+01, -1.0492e+00,  2.8627e+00,\n",
              "         5.5568e+00,  2.0619e+01,  1.3788e+01,  3.9416e+00,  1.3234e+01,\n",
              "         1.8243e+01,  4.9692e+00,  1.4729e+01,  9.4403e+00,  9.3407e+00,\n",
              "         2.0997e+01,  8.6296e+00,  1.3453e+00,  1.0368e+01,  9.2893e+00,\n",
              "         1.2335e+01,  1.5519e+01,  1.7299e+01,  3.2561e+00,  1.1221e+01,\n",
              "         1.5347e+01,  9.0113e+00,  3.6505e+00,  1.0165e+01,  9.6867e+00,\n",
              "         1.4483e+01,  9.2409e+00,  7.8825e-01,  1.2057e+01,  2.4606e+00,\n",
              "         2.0253e+01,  1.7504e+01,  1.6911e+01,  8.8917e+00,  1.5198e+01,\n",
              "         1.9341e+00,  2.0112e+01,  1.6320e+01,  1.9322e+01, -1.5887e+00,\n",
              "         3.5921e+00,  2.9585e+00,  1.2216e+01,  1.2481e+01,  2.2631e+01,\n",
              "         1.4145e+01,  1.0764e+01,  7.8268e+00,  9.4099e+00,  9.5086e+00,\n",
              "         1.5979e-02,  2.9096e+00,  1.8475e+01,  1.0839e+01,  8.9455e+00,\n",
              "         1.7468e+01,  1.2970e+01,  7.4026e+00,  1.6392e+01,  1.2110e+01,\n",
              "         1.6045e+01,  5.0966e-02,  1.2489e+01,  1.5185e+01,  8.1080e+00,\n",
              "         1.6829e+00,  8.6784e+00,  1.3827e+01,  5.7060e+00,  6.9811e+00,\n",
              "         1.2563e+01,  1.2027e+01,  1.3344e+01,  1.1499e+01,  1.4045e+01,\n",
              "         2.0255e+01,  1.4695e+01,  1.2829e+01,  6.9367e+00,  1.4722e+01,\n",
              "         1.7617e+01,  2.3188e+01,  8.9784e+00,  1.3618e+01,  1.3314e+01,\n",
              "         1.4109e+01, -4.2060e+00,  1.6402e+01,  6.6189e+00,  7.0618e+00,\n",
              "         1.1894e+01,  1.4114e+01,  5.6702e+00,  3.2031e+00,  8.3505e+00,\n",
              "         8.9748e+00,  3.6721e+00,  8.8963e+00,  4.2436e+00,  7.0899e+00,\n",
              "         1.8694e+01,  3.1997e+00,  1.2059e+01,  2.2210e+01,  1.2376e+01,\n",
              "         9.6381e+00,  1.7282e+01,  9.3255e+00,  1.6206e+01,  2.8677e+01,\n",
              "         8.7143e+00,  5.7770e+00,  5.0801e+00,  7.0600e+00,  8.2724e+00,\n",
              "         7.2723e+00,  8.5558e+00,  1.5545e+01, -3.1608e+00,  3.7112e+00,\n",
              "        -8.3093e+00, -4.9009e+00,  7.3758e+00,  1.9430e+01,  4.4660e+00,\n",
              "         7.6896e+00,  2.7034e+00,  1.0809e+01,  1.1839e+01,  1.2620e+01,\n",
              "         8.1873e+00,  1.1198e+01,  2.2130e+01,  1.1644e+01,  2.6200e+00,\n",
              "         1.4674e+01,  5.3565e+00,  7.3635e+00,  1.6746e+01,  1.5116e+01,\n",
              "         1.9371e+00,  1.5474e+01, -2.1860e+00,  1.1049e+01,  1.5066e+01,\n",
              "         1.6891e+01, -1.3066e+00,  1.5219e+01,  7.8972e+00,  8.0766e+00,\n",
              "        -1.0597e+00,  8.2011e+00,  1.5139e+01, -7.5599e-01, -6.4438e+00,\n",
              "         1.4943e+01,  3.1580e-01,  1.9194e+00,  9.8855e+00,  6.6666e+00,\n",
              "         1.2573e+01,  9.4051e+00,  1.2266e+01,  8.8191e+00,  5.0355e+00,\n",
              "         9.8726e+00,  6.9207e+00,  1.2368e+01,  1.6259e+01,  1.5754e+01,\n",
              "         1.1372e+01,  1.1107e+01, -2.2010e+00,  1.0338e+01,  1.7280e+01,\n",
              "         1.3402e+01,  5.4223e+00,  4.0369e+00,  5.8967e+00,  1.0514e+01,\n",
              "         6.3701e+00,  9.0216e+00,  8.9129e+00,  6.3545e+00,  1.2374e+01,\n",
              "         7.0512e+00,  1.1444e+01,  8.0715e+00, -9.3678e+00,  7.1116e+00,\n",
              "         6.7224e+00, -1.6491e+00,  6.9857e+00,  2.9856e+00,  3.6281e+00,\n",
              "         1.3920e+01,  8.5908e+00,  1.9847e+01,  1.4605e+01,  7.6068e+00,\n",
              "         1.3926e+01,  2.4923e+00,  1.7045e+01,  2.6159e+01, -6.0559e-01,\n",
              "         1.0458e+01,  8.0111e+00,  1.0918e+01,  8.0086e+00,  1.2580e+01,\n",
              "         1.6389e+01,  1.1601e+01,  7.0759e+00,  1.7251e+01,  7.2678e+00,\n",
              "         8.3110e+00,  1.7016e+01,  1.1792e+01,  1.6093e+01,  1.6967e+01,\n",
              "         2.3533e+00,  5.8309e+00,  6.3465e+00,  1.3910e+01,  1.4376e+01,\n",
              "         8.2865e+00,  2.0114e+01,  1.6891e+01,  1.7079e+01,  1.1347e+01,\n",
              "         5.4285e+00,  1.6351e+01,  7.3252e+00,  2.1128e+01,  5.5259e+00,\n",
              "         1.1980e+01,  1.1084e+01,  1.1604e+01,  1.1020e+01,  3.9433e+00,\n",
              "        -5.7719e+00,  1.1441e+01,  1.1045e+01,  1.8287e+01,  5.9910e+00,\n",
              "         2.5849e+01,  1.2283e+01,  1.0769e+01,  1.1962e+01,  2.1134e+01,\n",
              "         1.4459e+01,  6.0735e+00,  1.3275e+01,  1.6214e+01,  1.1710e+01,\n",
              "         8.0015e+00,  6.2014e+00,  1.7804e+01,  1.7751e+01,  6.7559e+00,\n",
              "         1.0756e+01,  9.0260e+00,  4.6102e+00,  3.8740e+00,  1.3181e+01,\n",
              "         2.5507e+01,  6.1745e+00,  6.8076e+00,  4.3609e+00,  1.2266e+01,\n",
              "        -1.0712e-01,  7.1267e+00, -2.8311e-01,  1.3833e+01,  1.3210e+01,\n",
              "         1.4163e+01,  3.9586e+00,  1.2465e+01,  1.4662e+01,  7.6376e+00,\n",
              "         4.7317e+00,  5.2415e+00,  2.5402e+00,  1.1552e+01,  1.0699e+01,\n",
              "         1.6689e+01,  2.0663e+01,  1.7039e+00,  1.5556e+01,  1.2046e+01,\n",
              "         5.7084e+00,  1.6479e+01,  1.4551e+01,  9.9329e+00,  1.2284e+00,\n",
              "         2.7236e+01,  4.1662e+00,  1.7750e+01,  2.0745e+01,  8.5993e+00,\n",
              "         7.8233e+00,  1.1060e+01,  2.1859e+00,  1.2412e+01,  7.5027e+00,\n",
              "         2.8063e-01,  1.5741e+01,  9.4632e-01,  1.2163e+01,  9.6249e+00,\n",
              "         4.9527e+00,  3.3329e+00,  1.3988e+01,  1.0410e+01,  6.3100e+00,\n",
              "         7.0746e+00,  1.4243e+01,  1.3237e+01,  6.6889e+00,  1.2215e+01,\n",
              "         4.8083e+00,  1.5699e+01,  1.7828e+01,  2.0692e+01,  9.7826e+00,\n",
              "         1.7014e+01,  1.0524e+01,  8.0510e+00,  6.8744e+00,  3.2670e+01,\n",
              "         1.5025e+01,  1.0702e+01, -2.0591e+00,  1.8070e+00,  5.1435e+00,\n",
              "         8.8019e+00,  3.0409e-01,  1.1879e+01,  1.1566e+01,  1.7176e+01,\n",
              "         1.0774e+01,  1.0534e+01,  1.3171e+01,  7.4028e-01, -7.0783e+00,\n",
              "         5.0109e+00,  1.0418e+01,  1.5575e+01,  1.0254e+01,  6.8120e+00,\n",
              "        -4.0186e+00,  5.1778e+00,  1.4140e+01,  1.6884e+00,  5.7353e+00,\n",
              "         8.9011e+00,  8.2998e+00,  1.6419e+01,  8.5737e+00,  1.5081e+01,\n",
              "         5.3851e+00,  2.2247e+01,  4.3952e+00,  1.2277e+01,  3.1517e+00,\n",
              "         5.1425e+00,  8.2480e+00,  1.1065e+01, -2.0446e-01,  1.2217e+01,\n",
              "         7.4572e+00,  6.7341e+00,  1.5232e+01,  4.9182e-01,  2.0337e+01,\n",
              "         9.2248e+00,  1.8352e+01,  8.1072e+00,  9.4227e+00,  1.3048e+01,\n",
              "         1.7646e+01,  1.0061e+01,  7.4910e+00,  1.7229e+01,  1.0778e+01,\n",
              "         1.2002e+01,  1.2183e+01,  4.9592e+00,  2.0859e+01,  1.1237e+01,\n",
              "         1.2881e+01,  6.7808e+00,  2.2052e+01,  1.2901e+01,  1.6960e+01,\n",
              "         2.6915e+01,  5.5262e+00,  1.3444e+01, -1.7258e+00,  2.2975e+00],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize the 5 dimensions of the linear regression problem\n",
        "\n",
        "Use the scatter plot to visualise the 4 dimensions of the X_train as 3 spatial and 1 size dimensions.The 1 dimension of y_train is visualiszed as the color on the scatter plot.\n",
        "\n",
        "*   The scale setting is configure to 1,000 for a better looking visualisation and does not change the original multivariate linear regression problem.\n",
        "\n",
        "*   The stride setting is configured to 25 by default.You can choose more data points out of TRAINING_DATASET_SIZE to visualize by setting STRIDE to be closer to 1, or fewer data points to visulze by using a Stride value closer to TRAINING_DATASET_SIZE.\n",
        "\n"
      ],
      "metadata": {
        "id": "OklSADyz_YPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib  inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "figure = plt.figure(figsize = (16, 9))\n",
        "axis = Axes3D(figure, rect = [0, 0, .95, 1], elev=48, azim=134)\n",
        "\n",
        "SCALE = 1_000\n",
        "y_view, X_view = SCALE * y_train, SCALE * X_train\n",
        "\n",
        "STRIDE = 25\n",
        "pc = axis.scatter(X_view[::STRIDE, 0], X_view[::STRIDE, 1], X_view[::STRIDE, 2], s = X_view[::STRIDE, 3], c = y_train[::STRIDE])\n",
        "figure.colorbar(pc, fraction = 0.01)\n",
        "axis.set_xlabel('x0'), axis.set_ylabel('x1'), axis.set_zlabel('x2');\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "PDt2JvZIArJw",
        "outputId": "b865803e-487d-4876-de22-f248f860f0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x900 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create random values for the initial model parameters\n",
        "*   create a w_numpy nd-array shaped (FEATURES, 1) with the model parameter values\n",
        "*   You can use normally distributed randn values or try a more complex initialization scheme\n",
        "\n"
      ],
      "metadata": {
        "id": "f28vuqJvFygT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_numpy = np.random.randn(FEATURES, 1)\n",
        "w_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNKzPSvF_O2w",
        "outputId": "3cacc4e1-a97c-41a3-9124-1fbd6f8ebf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.8634936 ],\n",
              "       [-0.03120349],\n",
              "       [ 0.01801687],\n",
              "       [ 0.47263035]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instantiate a differentiable tensor w as the model\n",
        "\n",
        "- the w tensor should use w_numpy and use pt.float64 as the dtype\n",
        "- recall that requires_grad must be True for a PyTorch tensor to be differentiable\n",
        "- You can use torch.randn to initialize the values or try a more complex scheme like torch.nn.init.kaiming_uniform_\n",
        "- implement the forward and mse functions for the model"
      ],
      "metadata": {
        "id": "LORLtffPHY1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = pt.tensor(w_numpy, requires_grad=True, dtype=pt.float64)\n",
        "w\n",
        "\n",
        "def forward (w, X):\n",
        "  return (X @ w).reshape(X.shape[0])\n",
        "\n",
        "def mse(y_est, y):\n",
        "  err = y_est - y\n",
        "  return(err**2).mean()\n",
        "\n",
        "mse(forward(w, X_train), y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4T9dATCIUr7",
        "outputId": "f0ce689a-2195-4cf7-8fa3-583d44b20afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(122.5371, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Solve for the cofficients using ordinary gradient descent\n",
        "For consistency, with the upcoming parts of the notebook use\n",
        "- EPOCHS = 400\n",
        "- LEARNING_RATE = 0.01"
      ],
      "metadata": {
        "id": "qCVUU7_dIqyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 400\n",
        "LEARNING_RATE = 0.01"
      ],
      "metadata": {
        "id": "_GKJ6MKtKc1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recover the cofficients from the data using ordinary gradient descent\n",
        "- the entire training dataset is used to compute the gradients per iteration of gradient descent\n"
      ],
      "metadata": {
        "id": "IM5BZS6mKpJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  y_est = forward(w, X_train)\n",
        "  loss = mse(y_est, y_train)\n",
        "  loss.backward()\n",
        "\n",
        "  w.data -= LEARNING_RATE * w.grad\n",
        "  w.grad = None\n",
        "\n",
        "w.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bwdKxzBK-U9",
        "outputId": "d576e8a9-9d93-452d-b5f0-e829425b1805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.9967],\n",
              "        [2.9996],\n",
              "        [1.9992],\n",
              "        [1.0007]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if the training dataset dosen't fit in -memory of the node?\n",
        "\n",
        "Gradient Descent using Gradient Accumulation\n",
        "\n",
        "- Single node, in-memory implementation\n",
        "- For example, an in- memory shard(a part of the training dataset) can consist of 250 training examples.\n",
        "\n",
        "\n",
        "Training            Shared Model   Los Function Sequencial\n",
        "Datasets            Parameters      Gradients\n",
        "Shards               (Weights)\n",
        "\n",
        "          \n",
        "\n",
        "[0   :250]o  ------>     --------> g 0              sequential Gradient\n",
        "[250:500]1  ------->  w  -------> g 1 + g0          Accumulation\n",
        "[500:750]2 -------->     --------> g2 + g1 + g0\n",
        "[750:]3 ----------->     ---------> (g3 +g2 + g1 + g0)\n",
        "w -=LEARNING_RATE *(g3 + g2 + g1 + g0)"
      ],
      "metadata": {
        "id": "fObYlXKpbv-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IN_MEORY_SHARD_SIZE = 250\n",
        "w = pt.tensor(w_numpy, requires_grad=True, dtype=pt.float64)\n",
        "from torch.utils.data import TensorDataset,DataLoader"
      ],
      "metadata": {
        "id": "qEklLFfduXSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single node gradient descent with gradient accumulation\n",
        "- use TensorDataset and DataLoader from the torch.utils.data package\n",
        "- Use IN_MEMORY_SHARD_SIZE / TRAINING_DATASET_SIZE to ajust the loss function for the shard size\n",
        "- Demonstrate gradient accumulation vs mini-batch gradient descent explaining shards vs training vs training batches."
      ],
      "metadata": {
        "id": "VehboU9ru4aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IN_MEMORY_SHARD_SIZE = 250 # Define the variable here\n",
        "LEARNING_RATE = 0.01 # Define the learning rate\n",
        "\n",
        "training_ds = TensorDataset(y_train, X_train) # Define the TensorDataset\n",
        "train_d1 = DataLoader(training_ds, batch_size=IN_MEMORY_SHARD_SIZE, shuffle=False) #use shuffle=True\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for y_shard, X_shard in train_d1:\n",
        "    y_est = forward(w, X_shard)\n",
        "    loss = (IN_MEMORY_SHARD_SIZE / TRAINING_DATASET_SIZE) * ((y_est -  y_shard) **2).sum() * (1/ IN_MEMORY_SHARD_SIZE)\n",
        "    loss.backward()\n",
        "    w.data -= LEARNING_RATE *  w.grad # Use the correct variable name here\n",
        "    w.grad = None"
      ],
      "metadata": {
        "id": "IBopLbui2rBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IN_MEMORY_SHARD_SIZE = 250 # Define the variable here\n",
        "LEARNING_RATE = 0.01 # Define the learning rate\n",
        "\n",
        "training_ds = TensorDataset(y_train, X_train) # Define the TensorDataset\n",
        "train_d1 = DataLoader(training_ds, batch_size=IN_MEMORY_SHARD_SIZE, shuffle=False) #use shuffle=True\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for y_shard, X_shard in train_d1:\n",
        "    y_est = forward(w, X_shard)\n",
        "    loss = mse(y_est, y_shard)\n",
        "    loss.backward()\n",
        "    w.data -= LEARNING_RATE *  w.grad # Use the correct variable name here\n",
        "    w.grad = None"
      ],
      "metadata": {
        "id": "0H4cuXw-z6Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW-M67z40V1y",
        "outputId": "8b98b151-a91c-475a-d878-b084840819ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.0000],\n",
              "        [3.0000],\n",
              "        [2.0000],\n",
              "        [1.0000]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can gradient accumulation help distribute gradient descent?\n",
        "## Parameter server-based distributed (multi-node) gradient descent\n",
        "\n"
      ],
      "metadata": {
        "id": "TGKEnr2Fv9Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NODES = TRAINING_DATASET_SIZE // IN_MEMORY_SHARD_SIZE\n",
        "\n",
        "GRADIENTS = [5, 3, 2, 1]\n",
        "GRADIENTS\n",
        "\n",
        "node_to_gradients = dict(zip(range(NODES), GRADIENTS))\n",
        "node_to_gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDv7fgIr33Re",
        "outputId": "095d1cad-f856-4cdb-e7f2-3b8f004f6000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5, 1: 3, 2: 2, 3: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All-Gather Operation Example (not Horovod)"
      ],
      "metadata": {
        "id": "r9qhnvEh4oUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstarte 3 iterations with 4 nodes\n",
        "- Assuming iteration 0 has node 1 start communication , after 3 iterations the gradients should be accumulated (reduced) on node 0."
      ],
      "metadata": {
        "id": "zWgq_0oK8Nf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(NODES - 1):\n",
        "   node = (iter + 1) % NODES\n",
        "   grad = node_to_gradients[node]\n",
        "\n",
        "   next_node = (node + 1) % NODES\n",
        "   node_to_gradients[next_node] += grad # Fixed typo here: node_to_gradients\n",
        "\n",
        "node_to_gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxxqTzkG_HTv",
        "outputId": "b718b64e-0762-4a10-9cc9-ee143d7fc711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 11, 1: 3, 2: 5, 3: 6}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Horovod:A ring-based distributed gradient descent\n",
        "- **Distributed Data Parallel**  approach using (1) reduce-scatter and (2) all-gather phases\n",
        "- more bandwidth efficient than parameter server based approaches and plain all-gather\n",
        "- not to be confused with Hovorod the machine learning framework\n",
        "- also not to be confused with Horovod the Slavic folk dance which inspired the name\n",
        "\n"
      ],
      "metadata": {
        "id": "RQHFSPGq_Oxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Partitioning gradients into \"segments\"\n",
        "\n",
        "- having a segment of the gradients enables Horovod to decrease the amount of bandwidth needed to complete the reduce-all operation, in other words, to deliver the sum of the gradients for each shard to every node in the ring.\n",
        "- by default there are as many segments as nodes\n",
        "\n",
        "training  -->  Gradient ---> Gradients\n",
        "dataset         Tensor        Tensor Segments\n",
        "shard"
      ],
      "metadata": {
        "id": "Xk7ygrKnKCWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent with Horovod\n",
        "\n",
        "- Create a list of tensors w with NODES tensors based on w_numpy values\n",
        "- recall that each of the tensors in the list w must have requires_grad set to True"
      ],
      "metadata": {
        "id": "J4mRTiJ1MRPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = [pt.tensor(w_numpy, requires_grad=True, dtype=pt.float64) for _ in range(NODES)]\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ftah7MpKrVi",
        "outputId": "08da1785-a526-4f82-9774-10607d0702a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.8635],\n",
              "         [-0.0312],\n",
              "         [ 0.0180],\n",
              "         [ 0.4726]], dtype=torch.float64, requires_grad=True),\n",
              " tensor([[-0.8635],\n",
              "         [-0.0312],\n",
              "         [ 0.0180],\n",
              "         [ 0.4726]], dtype=torch.float64, requires_grad=True),\n",
              " tensor([[-0.8635],\n",
              "         [-0.0312],\n",
              "         [ 0.0180],\n",
              "         [ 0.4726]], dtype=torch.float64, requires_grad=True),\n",
              " tensor([[-0.8635],\n",
              "         [-0.0312],\n",
              "         [ 0.0180],\n",
              "         [ 0.4726]], dtype=torch.float64, requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perform a single forward pass of gradient descent for every node\n",
        "- you use zip On range(NODES) and train_d1"
      ],
      "metadata": {
        "id": "68-hnRFVNakj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for node,(y_shard, X_shard) in zip(range(NODES), train_d1 ):\n",
        "   y_est = forward(w[node], X_shard)\n",
        "   loss = (IN_MEMORY_SHARD_SIZE /TRAINING_DATASET_SIZE) * mse(y_est, y_shard)\n",
        "   loss.backward()"
      ],
      "metadata": {
        "id": "BOxzgb6LNqok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output the gradient segments on each node"
      ],
      "metadata": {
        "id": "5oBOBW9jNt_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[f\"{w[node].grad}\" for node in range(NODES)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCs518BGOwfX",
        "outputId": "1e51b020-2bba-4314-c5e6-b4ee6feba67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tensor([[ -2.2359],\\n        [ -5.8035],\\n        [ -9.6787],\\n        [-13.6585]], dtype=torch.float64)',\n",
              " 'tensor([[ -2.8646],\\n        [ -6.7470],\\n        [-10.3750],\\n        [-14.6556]], dtype=torch.float64)',\n",
              " 'tensor([[ -2.6644],\\n        [ -6.0465],\\n        [ -9.4730],\\n        [-13.1745]], dtype=torch.float64)',\n",
              " 'tensor([[ -3.5390],\\n        [ -5.6735],\\n        [ -9.0646],\\n        [-13.0034]], dtype=torch.float64)']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Output the target sum of the gradients as the target for Horovod"
      ],
      "metadata": {
        "id": "UE4NamLSPOh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(w[node].grad for node in range(NODES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ijke1JhPiKb",
        "outputId": "7f730283-dd72-4b85-fea9-a7492810da4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-11.3039],\n",
              "        [-24.2705],\n",
              "        [-38.5913],\n",
              "        [-54.4920]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Horovod Phase 1: Reduce Scatter"
      ],
      "metadata": {
        "id": "mtzAKw7pPwyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<video width=\"960\" height=\"720\" autoplay loop muted playsinline controls>\n",
        "      <source src=\"https://i.imgur.com/IV6jBwL.mp4\" type=\"video/mp4\">\n",
        "      <video>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "51OnDO40P43n",
        "outputId": "ed4f2e9a-ee99-43c4-92d4-c82e96646fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"960\" height=\"720\" autoplay loop muted playsinline controls>\n",
              "      <source src=\"https://i.imgur.com/IV6jBwL.mp4\" type=\"video/mp4\">\n",
              "      <video>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#horovod phase. 1: reduce scatter\n",
        "for iter in range(NODES - 1):\n",
        "   for node in range(NODES):\n",
        "     seg = (node - iter - 1) % NODES\n",
        "     grad = w[node].grad[seg]\n",
        "\n",
        "     next_node = (node + 1) % NODES\n",
        "     w[next_node].grad[seg]+= grad"
      ],
      "metadata": {
        "id": "uQZrHOoDR6qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output the gradient segments on each node"
      ],
      "metadata": {
        "id": "INOuYysnSFEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[f\"{w[node].grad}\" for node in range(NODES)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdM0zkw_TMSh",
        "outputId": "284cc20b-4660-4275-bcad-0c4b475f11ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tensor([[-11.3039],\\n        [-17.5235],\\n        [-18.7433],\\n        [-13.6585]], dtype=torch.float64)',\n",
              " 'tensor([[ -2.8646],\\n        [-24.2705],\\n        [-29.1183],\\n        [-28.3140]], dtype=torch.float64)',\n",
              " 'tensor([[ -5.5290],\\n        [ -6.0465],\\n        [-38.5913],\\n        [-41.4886]], dtype=torch.float64)',\n",
              " 'tensor([[ -9.0680],\\n        [-11.7200],\\n        [ -9.0646],\\n        [-54.4920]], dtype=torch.float64)']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output just the reduced(accumulated) segment on each node"
      ],
      "metadata": {
        "id": "GoveCrMaUroG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[f\"{w[node].grad[node]}\" for node in range(NODES)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWPytqwJVE5f",
        "outputId": "724e7c73-1a01-46c3-f5f0-54774c0cbf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tensor([-11.3039], dtype=torch.float64)',\n",
              " 'tensor([-24.2705], dtype=torch.float64)',\n",
              " 'tensor([-38.5913], dtype=torch.float64)',\n",
              " 'tensor([-54.4920], dtype=torch.float64)']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Horovod Phase 2:All Gather"
      ],
      "metadata": {
        "id": "g3_XDHSsVnX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<video width=\"960\" height=\"720\" autoplay loop muted playsinline controls>\n",
        "      <source src=\"https://i.imgur.com/IV6jBwL.mp4\" type=\"video/mp4\">\n",
        "      <video>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "6z1hr4JPVr0Z",
        "outputId": "c7e38876-8d98-4557-f967-f4cd920a08e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"960\" height=\"720\" autoplay loop muted playsinline controls>\n",
              "      <source src=\"https://i.imgur.com/IV6jBwL.mp4\" type=\"video/mp4\">\n",
              "      <video>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#horovod phase 2: all gather\n",
        "for iter in range(NODES - 1):\n",
        "  for node in range(NODES):\n",
        "      seg = (node - iter) % NODES\n",
        "      grad = w[node].grad[seg]\n",
        "\n",
        "      next_node = (node + 1) % NODES\n",
        "      w[next_node].grad[seg] = grad"
      ],
      "metadata": {
        "id": "rWPafSK2W3gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output the gradients on each node"
      ],
      "metadata": {
        "id": "aQan8gYUXLMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[f\"{w[node].grad}\" for node in range(NODES)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWWh-oeAXRuU",
        "outputId": "ca54f190-2bc5-4f4b-a412-2080f1b541dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tensor([[-11.3039],\\n        [-24.2705],\\n        [-38.5913],\\n        [-54.4920]], dtype=torch.float64)',\n",
              " 'tensor([[-11.3039],\\n        [-24.2705],\\n        [-38.5913],\\n        [-54.4920]], dtype=torch.float64)',\n",
              " 'tensor([[-11.3039],\\n        [-24.2705],\\n        [-38.5913],\\n        [-54.4920]], dtype=torch.float64)',\n",
              " 'tensor([[-11.3039],\\n        [-24.2705],\\n        [-38.5913],\\n        [-54.4920]], dtype=torch.float64)']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bringing it all together"
      ],
      "metadata": {
        "id": "vk-MOJtJXSTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w =[pt.tensor(w_numpy, requires_grad=True) for _ in range(NODES)]\n",
        "\n",
        "EPOCHS = 400\n",
        "for epoch in range(EPOCHS):\n",
        "#Compute per batch gradients on each node\n",
        " for node,(y_shard, X_shard) in zip(range(NODES), train_d1):\n",
        "  y_est = forward(w[node], X_shard)\n",
        "  loss = (IN_MEMORY_SHARD_SIZE / TRAINING_DATASET_SIZE) * mse(y_shard, y_est)\n",
        "  loss.backward()\n",
        "\n",
        "#horovod phase 1: reduce-scatter\n",
        "for iter in range(NODES - 1):\n",
        "  for node in range(NODES):\n",
        "    seg = (node - iter - 1) % NODES\n",
        "    grad = w[node].grad[seg]\n",
        "\n",
        "    next_node = (node + 1) % NODES\n",
        "    w[next_node].grad[seg] += grad\n",
        "\n",
        " #horovod phase 2: all-gather\n",
        "for iter in range(NODES - 1):\n",
        "  for node in range(NODES):\n",
        "    seg = (node - iter - 1) % NODES\n",
        "    grad = w[node].grad[seg]\n",
        "\n",
        "    next_node = (node + 1) % NODES\n",
        "    w[next_node].grad[seg] = grad\n",
        "\n",
        " #perform a step of gradient descent\n",
        "for node in range(NODES):\n",
        "  w[node].data -= LEARNING_RATE * w[node].grad\n",
        "  w[node].grad = None\n",
        "\n",
        "for node in range(NODES):\n",
        "  print(w[node].data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo6vSyrGXXxz",
        "outputId": "bbb12c92-32d2-49f7-d7ce-90261f84e88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10.5948],\n",
            "        [24.1550],\n",
            "        [36.2763],\n",
            "        [55.1066]], dtype=torch.float64)\n",
            "tensor([[10.5948],\n",
            "        [24.1550],\n",
            "        [36.2763],\n",
            "        [55.1066]], dtype=torch.float64)\n",
            "tensor([[10.5948],\n",
            "        [24.1550],\n",
            "        [36.2763],\n",
            "        [55.1066]], dtype=torch.float64)\n",
            "tensor([[10.5948],\n",
            "        [24.1550],\n",
            "        [36.2763],\n",
            "        [55.1066]], dtype=torch.float64)\n"
          ]
        }
      ]
    }
  ]
}