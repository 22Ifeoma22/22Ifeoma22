{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22Ifeoma22/22Ifeoma22/blob/main/ImageClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgOuvaqLLOLd"
      },
      "source": [
        "# Machine Learning with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mREffSpBLOLd"
      },
      "source": [
        "## Enhancing an Image Classifier\n",
        "\n",
        "* Starting with `torchvision.models`\n",
        "* Retraining pretrained models\n",
        "* Modifying Network Layers\n",
        "* Understanding Effects of Network Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UHo6DnxLOLe"
      },
      "source": [
        "### Transfer learning\n",
        "\n",
        "An important concept and tool to use once you have some basic idea of constructing neural networks is *transfer learning*.  Many of the things that a particular model learns can be applied to other problems that are somewhat similar in domain.  For example—perhaps the most used example of this—a great deal of image recognion amounts to be able to recognize object borders, general lighting conditions, overall shading region identification, and other overall image features.  Even if a model happens to be trained to recognize, e.g. houses versus kittens, much of the same pattern recognition would be helpful in distinguishing trucks from elephants.  Especially since training complex models can be extremely slow, and also simply because other people have done a great deal of work in finding good tagged image collections, it would be nice to re-use much of that work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKf-5w1BLOLe"
      },
      "source": [
        "### Credit\n",
        "\n",
        "As with several of the other lessons, I utilize and graciously thank other authors who have provided wondeful examples.  In this case, I found a blog post and code by Gilbert Adjei titled [Transfer Learning with PyTorch](https://heartbeat.fritz.ai/transfer-learning-with-pytorch-cfcb69016c72).  Looking through a fairly large number of similar writeups, I found his the most accessible and manageable of these.  I make some small modifications, but the credit for the code goes primarily to Adjei.\n",
        "\n",
        "What Adjei looks at is using the pretrained `densenet121` model that is one of numerous image models included with PyTorch, and adapting it to identify images of cells that either are or are not parasitized by malaria.  A nice overview of densenet design is contained in the post [The Efficiency of Densenet](https://medium.com/@smallfishbigsea/densenet-2b0889854a92), by Hao Gao.  For this purpose, and of the image models in PyTorch would be similar to work with.  As an exercise, it would be good to try to apply the techniques in this lesson to other provided models, such as AlexNet, VGG, ResNet, SqueezeNet, Inception v3, GoogLeNet (most of those themselves come in a number of variations with differing layers, depths, and other design distinctions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsb745PNLOLe"
      },
      "source": [
        "### Getting started\n",
        "\n",
        "This lesson will take about 30-45 minutes to run, even with a fast GPU.  Probably many hours for CPU-only.  For those following along, it is a good idea to \"Run All Cells\" before we begin talking about the concepts.  \n",
        "\n",
        "We need a fairly large dataset to run this model.  The collection of images contains about 28k of them, evenly divided between \"Parasitized\" and \"Uninfected\" classes.  The archive of all the images is a bit over 300 MiB.  I have hosted it on my personal website for convenience.  The underlying dataset comes from the US [National Institutes of Health](https://ceb.nlm.nih.gov/repositories/malaria-datasets/).  In some basic testing, my web host seems to be faster than any of the NIH website, the Kaggle site where it is mirrored, or the Google Drive location where Adjei uploaded it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6m-_Qwy5LtwN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "from os.path import exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRqTKbTuL5LD",
        "outputId": "9a553f4d-cb78-49dd-9bb8-603b73583ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
            "License(s): unknown\n",
            "Downloading cell-images-for-detecting-malaria.zip to /content\n",
            "100% 674M/675M [00:34<00:00, 26.9MB/s]\n",
            "100% 675M/675M [00:34<00:00, 20.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download and unzip the dataset if not already done\n",
        "if not exists('data/cell_images/Parasitized') or not exists('data/cell_images/Uninfected'):\n",
        "    # Download the dataset\n",
        "    !kaggle datasets download -d iarunava/cell-images-for-detecting-malaria\n",
        "\n",
        "    # Unzip the dataset\n",
        "    with ZipFile('cell-images-for-detecting-malaria.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OX6L_qpaQhha"
      },
      "outputs": [],
      "source": [
        "\n",
        "from os.path import exists\n",
        "from os import remove\n",
        "from urllib.request import urlretrieve\n",
        "from zipfile import ZipFile\n",
        "\n",
        "if not exists ('data/cell_images/Parasitized') or\\\n",
        "    not exists('data/cell_images/Uninfected'):\n",
        "    fname, header = urlretrieve('http://gnosis.cx/download/cell_images.zip')\n",
        "\n",
        "    with ZipFile(fname) as zf:\n",
        "        zf.extractall('data/')\n",
        "    remove(fname)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bja0lE0BQ0Fs",
        "outputId": "bcbc19f4-b299-46a6-e14a-57671938eea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cell_images  Parasitized  Uninfected\n"
          ]
        }
      ],
      "source": [
        "# Check the contents of the directory\n",
        "!ls data/cell_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4j2a_bpLOLf"
      },
      "source": [
        "In this case, let us put all our imports together at the start, as we would in a standalone script.  In some notebooks I have interspersed the imports to emphasize what code they pertain to, but there are few enough here that the start is a better place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jTAOgd53LOLf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from glob import glob\n",
        "from random import randrange\n",
        "import os\n",
        "from time import time\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwj4xZ2TLOLf"
      },
      "source": [
        "As usual, let us try to use CUDA GPU if possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IQShXj40LOLg"
      },
      "outputs": [],
      "source": [
        "# For demonstration, we can use CPU target if CUDA not available\n",
        "device = torch.device('cpu')\n",
        "\n",
        "# Check the status of the GPU (if present)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA memory used:\", torch.cuda.memory_allocated())\n",
        "    device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbDziySqLOLg"
      },
      "source": [
        "#### A sample image\n",
        "\n",
        "Selected more-or-less at random, we can look at one typical image from the dataset to get a sense of what a cell image looks like.  The dimensions of the images are not completely uniform, but they are all of similar size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GLSocfiNTyEG",
        "outputId": "ee31e404-0852-46b6-c693-4ce6b1292ac4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(148, 142, 3)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the directory path\n",
        "data_dir = '/content/data/cell_images'  # Replace with the actual directory containing the images\n",
        "fname = 'Parasitized/C100P61ThinF_IMG_20150918_144104_cell_162.png'  # Replace with the correct image file name\n",
        "\n",
        "# Construct the full path to the image\n",
        "image_path = os.path.join(data_dir, fname)\n",
        "\n",
        "# Open the image\n",
        "try:\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Convert the image to a NumPy array and get its shape\n",
        "    image_array = np.array(image)\n",
        "    image_shape = image_array.shape\n",
        "\n",
        "    print(image_shape)\n",
        "except FileNotFoundError:\n",
        "    print(f\"The image file {image_path} does not exist.\")\n",
        "except IsADirectoryError:\n",
        "    print(f\"The path {image_path} is a directory, not a file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL5X7cnsLOLg"
      },
      "source": [
        "### Preparing images as inputs\n",
        "\n",
        "As we usually do when working with image data, we wish to perform a pipeline of image transforms on our raw images to give them all the same tensor size that we wish to work with.  This may involve sizing, cropping, color adjustment, and other normalization of the images.\n",
        "\n",
        "In the case of the training data, we add some additonal transforms to the pipeline.  In order to give the model a more robust set of training images, we randomly resize, flip, rotate, and add color jitter to the input images.  This should make the model capable of recognizing images that suffer from similar randomness in their original acquisition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uaCIxOL0LOLg"
      },
      "outputs": [],
      "source": [
        "# Define your transforms for the training, validation, and testing sets\n",
        "jitter_image = transforms.Compose([transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "                                   transforms.RandomRotation(degrees=15),\n",
        "                                   transforms.ColorJitter(),\n",
        "                                   transforms.RandomHorizontalFlip(),\n",
        "                                   transforms.CenterCrop(size=224),  # Image net standards\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                        [0.229, 0.224, 0.225])\n",
        "                                   ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3Is1Phm5LOLg"
      },
      "outputs": [],
      "source": [
        "clean_image = transforms.Compose([transforms.Resize(256),\n",
        "                                  transforms.CenterCrop(224),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                       [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sdJK5G8LOLg"
      },
      "source": [
        "### Loading the dataset\n",
        "\n",
        "Our dataset is based around the directory structure of our samples. Each of the subdirectories, `Parasitized/` and `Uninfected/` in this case, correspond to one class in the target. We further split up the dataset into three sampler for training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# Define transformations\n",
        "jitter_image = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Correct path to your image directory, if necessary.\n",
        "# If the 'data' directory is in the same directory as your notebook:\n",
        "data_dir = './data/cell_images/'\n",
        "\n",
        "# If the 'data' directory is elsewhere, provide the full path:\n",
        "# data_dir = '/path/to/your/data/cell_images/'\n",
        "\n",
        "# Load training data\n",
        "train_data = datasets.ImageFolder(data_dir, transform=jitter_image)\n",
        "\n",
        "# ... rest of your code ..."
      ],
      "metadata": {
        "id": "cVVdnsMIoif-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FENt21NLOLg",
        "outputId": "e599a3b4-bbb7-4009-9623-6ee0a212d844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 55116\n",
            "Classes: ['Parasitized', 'Uninfected', 'cell_images']\n",
            "Training: 38,582; Validation: 11,023; Testing: 5,511\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transformations\n",
        "jitter_image = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load training data from subdirectories indicating classes\n",
        "train_data = datasets.ImageFolder('data/cell_images/', transform=jitter_image)\n",
        "\n",
        "# Define a DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Print some information about the dataset\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Classes: {train_data.classes}\")\n",
        "\n",
        "# Load training data\n",
        "train_data = datasets.ImageFolder(data_dir, transform=jitter_image)\n",
        "# percentage of training set to use as validation & testing\n",
        "valid_size, test_size = 0.2, 0.1\n",
        "\n",
        "# Perform a train/test/validation split (sklearn train_test_split() might be more elegant)\n",
        "ntrain = len(train_data)\n",
        "indices = np.arange(ntrain)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "valid_split = int(valid_size * ntrain)\n",
        "test_split = int((valid_size+test_size) * ntrain)\n",
        "\n",
        "train_idx = indices[test_split:]\n",
        "valid_idx = indices[:valid_split]\n",
        "test_idx =  indices[valid_split:test_split]\n",
        "\n",
        "# Samplers for training, validation, and testing batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# Data loaders (combine dataset and sampler)\n",
        "params = {'batch_size': 32, 'num_workers': os.cpu_count()}\n",
        "train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, **params)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, sampler=valid_sampler, **params)\n",
        "test_loader = torch.utils.data.DataLoader(train_data, sampler=test_sampler, **params)\n",
        "\n",
        "print(f\"Training: {len(train_idx):,}; Validation: {len(valid_idx):,}; Testing: {len(test_idx):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transformations\n",
        "jitter_image = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load training data from subdirectories indicating classes\n",
        "train_data = datasets.ImageFolder('data/cell_images/', transform=jitter_image)\n",
        "\n",
        "# Define a DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Print some information about the dataset\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Classes: {train_data.classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7MhFIgfnjeu",
        "outputId": "02a63172-876f-4720-9275-6d7964006167"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 55116\n",
            "Classes: ['Parasitized', 'Uninfected', 'cell_images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH9e90ohVSwm"
      },
      "source": [
        "#Explanation and Improvements:\n",
        "Imports: Ensure you import all necessary modules and functions, such as datasets, transforms, DataLoader, SubsetRandomSampler, and os.\n",
        "\n",
        "#Transform Function:\n",
        "A transform function (jitter_image) is defined using transforms.Compose to apply color jitter and convert images to tensors.\n",
        "\n",
        "#Dataset Loading:\n",
        "The datasets.ImageFolder class is used to load images from the data_dir directory. This assumes that your dataset is structured such that each class has its own subdirectory.\n",
        "\n",
        "#Splitting the Dataset:\n",
        "The dataset indices are shuffled and then split into training, validation, and testing sets using array slicing.\n",
        "\n",
        "#Subset Samplers:\n",
        "SubsetRandomSampler instances are created for the training, validation, and test sets to ensure the data loaders only sample from the correct subsets.\n",
        "\n",
        "#Data Loaders:\n",
        "The DataLoader instances are created using the dataset and the respective samplers. The batch_size and num_workers parameters are set for efficient loading.\n",
        "\n",
        "#Printing Dataset Sizes:\n",
        "Finally, the sizes of the training, validation, and testing sets are printed.\n",
        "\n",
        "#Note:\n",
        "Ensure that the data_dir path points to the directory containing your image dataset.\n",
        "Make sure you have the torchvision package installed, which provides the datasets and transforms modules.\n",
        "This code provides a comprehensive approach to loading image data, applying transformations, and splitting it into training, validation, and testing sets for further use in training neural networks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzSvdf5cVLP8",
        "outputId": "f58134e6-328d-4127-8259-bddf1933a6d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: 38,582; Validation: 11,023; Testing: 5,511\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the transform function\n",
        "jitter_image = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load from subdirectories indicating classes\n",
        "data_dir = 'data/cell_images/'  # Update this path to your actual data directory\n",
        "train_data = datasets.ImageFolder(data_dir, transform=jitter_image)\n",
        "\n",
        "# Percentage of the training set to use as validation & testing\n",
        "valid_size, test_size = 0.2, 0.1\n",
        "\n",
        "# Perform a train/test/validation split\n",
        "ntrain = len(train_data)\n",
        "indices = np.arange(ntrain)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "valid_split = int(valid_size * ntrain)\n",
        "test_split = int((valid_size + test_size) * ntrain)\n",
        "\n",
        "train_idx = indices[test_split:]\n",
        "valid_idx = indices[:valid_split]\n",
        "test_idx = indices[valid_split:test_split]\n",
        "\n",
        "# Samplers for training, validation, and testing batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# Data loaders (combine dataset and sampler)\n",
        "params = {'batch_size': 32, 'num_workers': os.cpu_count()}\n",
        "train_loader = DataLoader(train_data, sampler=train_sampler, **params)\n",
        "valid_loader = DataLoader(train_data, sampler=valid_sampler, **params)\n",
        "test_loader = DataLoader(train_data, sampler=test_sampler, **params)\n",
        "\n",
        "print(f\"Training: {len(train_idx):,}; Validation: {len(valid_idx):,}; Testing: {len(test_idx):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssoOgW5jLOLg"
      },
      "source": [
        "### Load then enhance the pre-trained model\n",
        "\n",
        "By freezing the parameters in the trained model, and only adding extra layers, what we accomplish is turning the entire previous model into basically just a utility for feature engineering.  Densenet121 is just a fancy way of generating some high level synthetic features that we would like to use in **our** model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBPN6OuPLOLg",
        "outputId": "45f7fcbb-f3f6-41d4-b873-ada44e5249a8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 114MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DoQsfeyyLOLg"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.require_grad = False\n",
        "\n",
        "# Define our own network, layers after the existing model, but basically just treating\n",
        "# the pre-trained classifier as a feature engineering step\n",
        "classifier = nn.Sequential(\n",
        "                nn.Linear(1024, 460),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.4),\n",
        "                nn.Linear(460,2),\n",
        "                nn.LogSoftmax(dim=1)\n",
        "            )\n",
        "\n",
        "model.classifier = classifier.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# We want to only update the parameters of the classifier\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.003)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hNfWyJhLOLg"
      },
      "source": [
        "### Training the enhanced model\n",
        "\n",
        "In the training loop below, we do something that is good general practice.  After each epoch, we see whether that epoch has the best loss (or meets some other metric we are aiming for) and snapshot it only if it represents an improvement.  When we load the model later, we will be working with the best epoch.  Of course, we could also later try further training the model with more epochs and/or new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4JrBAG0Wwa_",
        "outputId": "1111bf1c-6919-4204-a0bc-9570877f8cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:01<00:00, 30.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1/10\n",
            "Training: .........."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import numpy as np\n",
        "import os\n",
        "from time import time\n",
        "from PIL import Image\n",
        "\n",
        "# Define device for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations for the training data and validation data\n",
        "jitter_image = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Ensure all images are 224x224\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "data_dir = 'data/cell_images/'\n",
        "train_data = datasets.ImageFolder(data_dir, transform=jitter_image)\n",
        "\n",
        "# Percentage of data to use for validation and testing\n",
        "valid_size, test_size = 0.2, 0.1\n",
        "\n",
        "# Split the data into train/validation/test\n",
        "ntrain = len(train_data)\n",
        "indices = np.arange(ntrain)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "valid_split = int(valid_size * ntrain)\n",
        "test_split = int((valid_size + test_size) * ntrain)\n",
        "\n",
        "train_idx = indices[test_split:]\n",
        "valid_idx = indices[:valid_split]\n",
        "test_idx = indices[valid_split:test_split]\n",
        "\n",
        "# Define samplers for training, validation, and test sets\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# Create DataLoaders\n",
        "params = {'batch_size': 32, 'num_workers': os.cpu_count(), 'pin_memory': True}\n",
        "train_loader = DataLoader(train_data, sampler=train_sampler, **params)\n",
        "valid_loader = DataLoader(train_data, sampler=valid_sampler, **params)\n",
        "test_loader = DataLoader(train_data, sampler=test_sampler, **params)\n",
        "\n",
        "# Define the model (using a pre-trained model as an example)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(train_data.classes))  # Adjust the final layer\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training settings\n",
        "epochs = 10\n",
        "valid_loss_min = np.Inf  # Initialize best loss as infinity\n",
        "model_save_name = \"Malaria.pt\"\n",
        "path = f\"data/{model_save_name}\"\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"EPOCH {epoch+1}/{epochs}\")\n",
        "    start = time()\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    print(\"Training: \", end='')\n",
        "    for n, (inputs, labels) in enumerate(train_loader):\n",
        "        try:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logps = model(inputs)\n",
        "            loss = criterion(logps, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            if n % 20 == 0:\n",
        "                print('.', end='', flush=True)\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError in training loop: {e}\")\n",
        "            continue\n",
        "    print(f\" {n+1} loops\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    print(\"Validating: \", end='')\n",
        "    accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for n, (inputs, labels) in enumerate(valid_loader):\n",
        "            try:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                logps = model(inputs)\n",
        "                batch_loss = criterion(logps, labels)\n",
        "                valid_loss += batch_loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                ps = torch.exp(logps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                if n % 10 == 0:\n",
        "                    print('.', end='', flush=True)\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError in validation loop: {e}\")\n",
        "                continue\n",
        "        print(f\" {n+1} loops\")\n",
        "\n",
        "    # Calculate average losses and accuracy\n",
        "    train_loss /= len(train_loader)\n",
        "    valid_loss /= len(valid_loader)\n",
        "    valid_accuracy = accuracy / len(valid_loader)\n",
        "\n",
        "    # Print training/validation statistics\n",
        "    print(f'Training Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_accuracy:.3f}')\n",
        "\n",
        "    # Save the model if the validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(f'Saving model... Validation loss decreased ({valid_loss_min:.3f} --> {valid_loss:.3f})')\n",
        "        torch.save(model.state_dict(), path)\n",
        "        valid_loss_min = valid_loss\n",
        "    else:\n",
        "        print(f'Not saving, validation loss did not improve.')\n",
        "\n",
        "    print(f\"Time for epoch: {int(time() - start)} seconds\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk5bSCmiWORS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import numpy as np\n",
        "import os\n",
        "from time import time\n",
        "\n",
        "# Define device for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations for the training data and validation data\n",
        "jitter_image = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "data_dir = 'data/cell_images/'\n",
        "train_data = datasets.ImageFolder(data_dir, transform=jitter_image)\n",
        "\n",
        "# Percentage of data to use for validation and testing\n",
        "valid_size, test_size = 0.2, 0.1\n",
        "\n",
        "# Split the data into train/validation/test\n",
        "ntrain = len(train_data)\n",
        "indices = np.arange(ntrain)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "valid_split = int(valid_size * ntrain)\n",
        "test_split = int((valid_size + test_size) * ntrain)\n",
        "\n",
        "train_idx = indices[test_split:]\n",
        "valid_idx = indices[:valid_split]\n",
        "test_idx = indices[valid_split:test_split]\n",
        "\n",
        "# Define samplers for training, validation, and test sets\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# Create DataLoaders\n",
        "params = {'batch_size': 32, 'num_workers': os.cpu_count()}\n",
        "train_loader = DataLoader(train_data, sampler=train_sampler, **params)\n",
        "valid_loader = DataLoader(train_data, sampler=valid_sampler, **params)\n",
        "test_loader = DataLoader(train_data, sampler=test_sampler, **params)\n",
        "\n",
        "# Define the model (using a pre-trained model as an example)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(train_data.classes))  # Adjust the final layer\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training settings\n",
        "epochs = 10\n",
        "valid_loss_min = np.Inf  # Initialize best loss as infinity\n",
        "model_save_name = \"Malaria.pt\"\n",
        "path = f\"data/{model_save_name}\"\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"EPOCH {epoch+1}/{epochs}\")\n",
        "    start = time()\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    print(\"Training: \", end='')\n",
        "    for n, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logps = model(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        if n % 20 == 0:\n",
        "            print('.', end='', flush=True)\n",
        "    print(f\" {n+1} loops\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    print(\"Validating: \", end='')\n",
        "    accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for n, (inputs, labels) in enumerate(valid_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            logps = model(inputs)\n",
        "            batch_loss = criterion(logps, labels)\n",
        "            valid_loss += batch_loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            ps = torch.exp(logps)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "            if n % 10 == 0:\n",
        "                print('.', end='', flush=True)\n",
        "        print(f\" {n+1} loops\")\n",
        "\n",
        "    # Calculate average losses and accuracy\n",
        "    train_loss /= len(train_loader)\n",
        "    valid_loss /= len(valid_loader)\n",
        "    valid_accuracy = accuracy / len(valid_loader)\n",
        "\n",
        "    # Print training/validation statistics\n",
        "    print(f'Training Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_accuracy:.3f}')\n",
        "\n",
        "    # Save the model if the validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(f'Saving model... Validation loss decreased ({valid_loss_min:.3f} --> {valid_loss:.3f})')\n",
        "        torch.save(model.state_dict(), path)\n",
        "        valid_loss_min = valid_loss\n",
        "    else:\n",
        "        print(f'Not saving, validation loss did not improve.')\n",
        "\n",
        "    print(f\"Time for epoch: {int(time() - start)} seconds\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cwz-27GYLOLg"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "valid_loss_min = np.Inf    # Initial best loss as infinite\n",
        "model_save_name = \"Malaria.pt\"\n",
        "path = f\"data/{model_save_name}\"\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"EPOCH\", epoch)\n",
        "    start = time()\n",
        "\n",
        "    # Notify the model we are in training mode\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    print(\"Training: \", end='')\n",
        "    for n, (inputs, labels) in enumerate(train_loader):\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logps = model(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        if not n % 20:\n",
        "            print('.', end='', flush=True)\n",
        "    print(n, \"loops\")\n",
        "\n",
        "    # Notify the model we are in eval mode (but also explicitly no_grad() for the work)\n",
        "    model.eval()\n",
        "    print(\"Validating: \", end='')\n",
        "    with torch.no_grad():\n",
        "        accuracy = 0\n",
        "        for n, (inputs, labels) in enumerate(valid_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            logps = model.forward(inputs)\n",
        "            batch_loss = criterion(logps, labels)\n",
        "            valid_loss += batch_loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            ps = torch.exp(logps)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "            if not n % 10:\n",
        "                print('.', end='', flush=True)\n",
        "        print(n, \"loops\")\n",
        "\n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    valid_loss = valid_loss/len(valid_loader)\n",
        "    valid_accuracy = accuracy/len(valid_loader)\n",
        "\n",
        "    # print training/validation statistics\n",
        "    print(f'Training Loss: {train_loss:.3f}')\n",
        "    print(f'Validation loss: {valid_loss_min:.3f} ⟶ {valid_loss:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_accuracy:.3f}')\n",
        "\n",
        "    # Only save the model if it is an improvement from best epoch\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(f'Saving model...')\n",
        "        torch.save(model.state_dict(), path)\n",
        "        valid_loss_min = valid_loss\n",
        "    else:\n",
        "        print(f'Not saving because not best epoch')\n",
        "\n",
        "    print(f\"Time for epoch: {int(time() - start)} seconds\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoPvAl9-LOLh"
      },
      "source": [
        "### Testing and visualizing results\n",
        "\n",
        "Here we use the test set that was held entirely separate from the training.  The validation was performed with `torch.no_grad()` in effect, but conceivably that dataset could have some systematic bias that produced inaccurate feedback into the loss function.  By testing against an entirely independent dataset, we get a good sanity check about our accuracy.\n",
        "\n",
        "In practice, if we do a reasonable train/test split on a reasonaly large dataset, there should be no important different between the validation and testing datasets, and we might often simply reuse the same dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS9bFEdgLOLh"
      },
      "outputs": [],
      "source": [
        "def test(model, criterion):\n",
        "# monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        # move to GPU\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss\n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "\n",
        "    print('Test Loss: {:.6f}'.format(test_loss))\n",
        "    print('Test Accuracy: %2d%% (%2d/%2d)' % (\n",
        "                100. * correct / total, correct, total))\n",
        "\n",
        "test(model, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gkq5B-WLOLh"
      },
      "source": [
        "#### Visualize a few categorized images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHQs5yO7LOLh"
      },
      "outputs": [],
      "source": [
        "def load_input_image(img_path):\n",
        "    image = Image.open(img_path)\n",
        "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
        "    image = clean_image(image)[:3,:,:].unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "def predict_malaria(model, class_names, img_path):\n",
        "    # load the image and return the predicted class\n",
        "    img = load_input_image(img_path)\n",
        "    model = model.cpu()\n",
        "    model.eval()\n",
        "    idx = torch.argmax(model(img))\n",
        "    return class_names[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6PJVEz4LOLh"
      },
      "outputs": [],
      "source": [
        "class_names=['Parasitized','Uninfected']\n",
        "inf = np.array(glob(\"data/cell_images/Parasitized/*\"))\n",
        "uninf = np.array(glob(\"data/cell_images/Uninfected/*\"))\n",
        "\n",
        "for _ in range(2):\n",
        "    i = randrange(len(inf))\n",
        "    fname = inf[i]\n",
        "    img = Image.open(fname)\n",
        "    if predict_malaria(model, class_names, fname) == 'Parasitized':\n",
        "        print(f'[{i}] Diagnosed Parasitized (CORRECT)')\n",
        "    else:\n",
        "        print(f'[{i}] Diagnosed Uninfected (MISTAKE)')\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for _ in range(2):\n",
        "    i = randrange(len(uninf))\n",
        "    fname = uninf[i]\n",
        "    img = Image.open(fname)\n",
        "    if predict_malaria(model, class_names, fname) == 'Uninfected':\n",
        "        print(f'[{i}] Diagnosed Uninfected (CORRECT)')\n",
        "    else:\n",
        "        print(f'[{i}] Diagnosed Parasitized (MISTAKE)')\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPAaBSqkLOLh"
      },
      "source": [
        "## Next Lesson\n",
        "\n",
        "We have looked at quite a few capabilities in PyTorch and associated tools.  The next step is to go out and use these lovely tools in your own projects.  I'd love to hear back on what you find and see what you create.  Contact me via the repository for this training material (file issues, email me, propose PRs, whatever).\n",
        "\n",
        "Thanks. David Mertz."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}